# ğŸ§  Ollama-GPT â€” Self-Hosted Private LLM with Open WebUI

Run your own **ChatGPT-like interface** entirely offline using:
- **[Ollama](https://ollama.com/)** â€” Run AI models locally on your own machine.
- **[Open WebUI](https://github.com/open-webui/open-webui)** â€” Beautiful ChatGPT-style interface.

> âš¡ **Privacy-first**: No API keys, no data sharing â€” 100% offline.

---

## ğŸ“¦ Features
- ğŸš€ Run open-source LLMs locally (LLaMA, CodeLLaMA, Qwen, Phi, etc.)
- ğŸ”’ Fully private â€” your data stays on your machine
- ğŸ³ Docker-based setup for quick deployment
- ğŸ’» CLI or Web UI access
- âš™ Configurable CPU & RAM limits

---

## ğŸš€ Setup Instructions

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/ashubambal/ollama-gpt.git
cd ollama-gpt

### 2ï¸âƒ£ Configure Environment Variables
Edit docker-compose.yml and set your own WEBUI_SECRET_KEY:
```bash
WEBUI_SECRET_KEY=enter-your-secret-key


